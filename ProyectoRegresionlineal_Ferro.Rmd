---
title: "Proyecto de regresión lineal"
output: html_notebook
---

```         
                            Ferro-Rodríguez Emiliano
```

En este proyecto analizaremos y crearemos un modelo de regresión líneal con los puntajes finales de estudiantes portugueses de nivel secundaria en las materias de Matemáticas y Portugués. Los datos student-mat.csv y student-psv contienen información de variables demográficas, sociales y escolares de cada estudiante, las cuales se detallan en el archivo student.txt.

**Objetivo**

Crear un modelo de regresión lineal múltiple que pueda predicir el puntaje final del último grado de cada estudiante (G3).

**Alcance:** Modelo de regresión líneal multiple para los puntajes de la materia de Matemáticas.

**Procedimiento:**

Lo primero que hacemos es llamar el dataset (student-mat.csv) y hacemos análisis estadístico.

```{r}
rm(list=ls())

Data = read.csv("student-mat.csv", header=TRUE, as.is = FALSE, sep = ";")
str(Data)

```

El dataset contiene 395 observaciones en 33 variables. Hacemos el resumen estadístico con la función *summary()* y con la función *pairs()* creamos gráficos de dispersión de las variables númericas.

```{r}
summary(Data)
pairs(Data[, c(3, 7, 8, 13, 14,15,24, 25)])
pairs(Data[, c(26, 27, 28, 29, 30, 31, 32, 33)])
```

El resumen estadístico nos dice que existen 17 variables de tipo caractér (school, sex, adress, famsize, Pstatus, Mjob, Fjob, reason, guardian, shcoolsup, famsup, paid, activities, nursery, higher, internet, romantic) y 16 variables de tipo numérico (age, Medu, Fedu, traveltime, studytime, famrel, goout, Dalc, Walc, absences, health, G1, G2 y G3).

Podemos observar en las gráficas de densidad, que G3 tiene un comportamiento líneal con las variables G1, G2 que son las calificaciones que obtuvieron los estudiantes en los 2 periodos (G1, G2). También podemos encontrar valores atípicos que son 0, eso quiere decir que hay alumnos que obtuvieron 0 de calificación, entonces es posible que estos valores afecten el análisis estadístico, por lo que tendremos que descartar esas calificaciones más algunos valores atípicos que afecten el análisis.

Con ayuda de *boxplots* podremos ver las relaciones de la variable G3 con las variables categóricas que muestren relaciones diferentes visibles.

Observamos la relación entre las calificaciones finales (G3) con el sexo (sex).

```{r}
boxplot(Data$G3[Data$sex == "F"],
Data$G3[Data$sex == "M"])

```

Observamos la relación entre las calificaciones finales (G3) y las actividades extracurriculares que toman algunos alumnos (activities).

```{r}
boxplot(Data$G3[Data$activities == "yes"], 
     Data$G3[Data$activities == "no"])
```

Observamos la relación de las calificaciones finales (G3) y la accesibilidad de los alumnos tienen internet (internet).

```{r}

boxplot(Data$G3[Data$internet == "yes"],
        Data$G3[Data$internet == "no"])
```

Con ayuda de estos *boxplots* podemos observar que la variable G3 tiene diferencias con las variables, *sex, e internet* parecen tener diferencias.

Ahora creamos un modelo de regresión líneal para la variable de calificaciones finales (G3).

Primero crearemos un modelo que incluya todas las variables predictoras. Además pedimos el resumen y las gráficas de residuales.

```{r}
Data = read.csv("student-mat.csv", header=TRUE, as.is = FALSE, sep = ";")
model1 = lm(G3 ~ ., data = Data) 
summary(model1)
plot(model1)
rsdls = residuals(model1)
shapiro.test(rsdls)

```

Lo que se logra observar en el modelo 1 es que tiene un error estandár residual de 1.9, este puede ser un poco alto. R cuadrada tiene un valor de 0.84 que nos dice que el modelo explica una gran parte de la variabilidad de la variable dependiente en este caso G3, pero este valor no es tan grande, entonces hay que ajustar el modelo para que posiblemente este valor aumente y tengamos una mejor predicción de la variable G3.

El p-valor de la prueba F es bajo, con ello nos dice que hay suficiente evidencia para rechazar la hipótesis nula concluyendo que al menos uno de los datos es significativo.

Lo que logro ver en las gráficas de residuales, es que los residuales no estan teniendo una distribución normal, y la prueba Sappiro nos lo demuestra ya que su p-valor es pequeño, esto concluye que hay suficiente evidencia para decir que los residuales no llevan una distribución normal.

El siguiente paso será ajustar el modelo para una mejor predicción y una distribución normal en los residuales. Primero eliminaré los valores atípicos y los 0 que se repiten para tener un mejor analisis descriptivo. Después pedimos el resumen estadístico y las gráficas de residuales del nuevo modelo ya ajustado; al final hacemos una prueba de shappiro para ver si los residuales logran tener una distribución normal.

```{r}
Data = read.csv("student-mat.csv", header=TRUE, as.is = FALSE, sep = ";")
Data = Data[-c(3, 34, 37, 44, 46, 62,101, 74, 79, 141, 175, 177,217, 260,  265, 342,371, 376), ]
Data = Data[Data$G3 != 0, ]
Data = Data[Data$G2 != 0, ]
Data = Data[Data$G1 != 0, ]
model2 = lm(G3 ~ ., data = Data) #Modelo bueno
summary(model2)
plot(model2)
residuales = residuals(model2)
shapiro.test(residuales)


```

Podemos observar una mejoría en el modelo, el error residual estándar bajó a 0.72, esto nos dice que el modelo tiene un mejor desempeño en la predicción de la variable G3. R cuadrada subió a 0.95, entonces podemos mencionar que el modelo 2 es buen modelo para poder predecir la variable dependiente en este caso las calificaciones finales de los alumnos. Y seguimos teniendo un p-valor bajo de la prueba F, por lo que seguimos rechazando la hipótesis nula y concluimos que al menos un dato es significativo.

Podemos ver la distribución líneal de los residuales, en la gráfica *Residuals vs Fitted* se observa un comportamiento líneal de los residuales; la gráfica Normal Q-Q, logra ver que los residuales tienen una distribución normal. Pero para comprobarlo hicimos la prueba de Shappiro; su p-valor tiene un valor de 0.081, por lo tanto existe suficiente evidencia de no rechazar la hipotesis nula, concluyendo que tenemos una distribución normal en los residuales.

Algo que noté al estar ajustando mi modelo líneal, es que si reduzco el modelo 1 poniendo solo las variables que tienen relación con G3, la predicción del modelo no disminuye, pero si aumenta un poco el error residual y se va perdiendo la distribución normal de los residuales.

```{r}
Data = read.csv("student-mat.csv", header=TRUE, as.is = FALSE, sep = ";")
Data = Data[-c(3, 34, 37, 44, 46, 62,101, 74, 79, 141, 175, 177,217, 260,  265, 342,371, 376), ]
Data = Data[Data$G3 != 0, ]
Data = Data[Data$G2 != 0, ]
Data = Data[Data$G1 != 0, ]
model3 = lm(G3 ~ age + Fjob + Mjob + higher + paid + activities + internet + traveltime + G1 +G2, data = Data) #Modelo bueno
summary(model3)
plot(model3)
residuales = residuals(model3)
shapiro.test(residuales)
```

Viendo las observaciones anteriores podemos decir que el **modelo 2** es válido para poder predecir las calificaciones finales de la materia de Matemáticas.

a)  ¿Qué tan grande es el impacto de los predictores en el puntaje final de los estudiantes?

    Es grande el impacto de los predictores en el puntaje final de los estudiantes, ya que aún tratando de reducir el modelo dejando solo las variables que tienen una relación líneal con la variable G3, los residuales terminan no teniendo una distribución normal.

b)  ¿El modelo elegido puede predecir bien a la variable respuesta?

    El modelo 2 puede predecir la mayoría de la variabilidad de la variable respuesta, porque el modelo puede predecir 95% de la variabilidad de la variable G3. Además del valor alto de R cuadrada, tenemos un valor de 0.72 en el error residual estandard, este es muy bajo, lo cual nos dice que los datos estan cerca de la línea de regresión, por lo que el modelo ajusta bien los datos.

    También la prueba F tiene un p-valor bajo, entonces hay suficiente evidencia para decir que al menos uno de los datos es significativo.

    Y por último en las gráficas de residuales, observamos un comportamiento líneal y normal en los residuales, y para confirmar el comportamiento normal de los residuales, la prueba Shappiro tiene un p-valor de 0.081, este valor es grande por lo que hay suficiente evidencia para no rechazar la hipótesis nula, por lo que los residuales tienen un comportamiento normal.

    Por lo anterior, podemos concluir que el modelo 2 logra predecir la variable respuesta.

c)  De intervalos de confianza y predicción para el puntaje final de los estudiantes considerando que los predictores toman tres posibles valores: cuartil 1, cuartil 2 y cuartil 3 para el caso de predictores continuos; si hubiese predictores discretos, es necesrio hacer la predicción para cada clase. ¿Cómo interpretaría estos intervalos?

    Para contestar la pregunta, creamos los intervalos de confianza oara los coeficientes de predicción con el comando *confint()*.

    ```{r}
    confint(model2)
    ```

    Se observa que solo existen 3 intervalos de confianza que nos son estrechos, son de las variables famrel, G1 y G2, eso nos indica que la predicción del parametro es precisa y tiene poca incertidumbre en torno a las variables, lo cual tiene sentido que sean al menos las variables G1 y G2 que son las únicas variables que tienen una relación líneal con G3. Lo interesante fue ver que también la variable famrel tenga relación positiva, aún cuando no se ve la relación en las gráficas de dispersión solo que el intervalo de confianza es amplio entonces no nos dice mucha información y crea incertidumbre, entonces solo analizaremos los casos de G1 y G2.

    Cada intervalo nos dice que se espera que el verdadero valor coeficiente del modelo de regresión esté dentro de los intervalosa un 95%. En el caso de G1 es (0.041, 0.16). Para G2 (0.82, 0.94).

Ahora creamos los intervalos de predicción del modelo 2, con cuantiles de 0.25, 0.50 y 0.75.

```{r}
new.data = data.frame(Data)
intervalo_confianza = predict(model2, newdata = new.data, interval = "confidence", level = 0.95)
intervalo_predicción = predict(model2, newdata = new.data, interval = "prediction", level = 0.95)

predicciones = predict(model2, interval = "prediction")

cuartiles_predicciones <- apply(predicciones, 2, quantile, probs = c(0.25, 0.5, 0.75))

cuartiles_predicciones_df <- as.data.frame(cuartiles_predicciones)


rownames(cuartiles_predicciones_df) <- c("Q1", "Q2", "Q3")


print(cuartiles_predicciones_df)


```

Lo que podemos concluir de estos intevalos de confianza es que el predictor puntual (fit) si se encuentra entre los datos del limite inferior (lwr) y el superior (upr), eso es muy bueno porque el modelo esta prediciendo bien las calificaciones finales. Esto nos dice que al 25% de las calificaciones estarán entre la calificación 7.76 y 10.73. Para el caso del 50% de las calificaciones estarán entre 9.88 y 12.9, y al final el 75% de las calificaciones estarán entre 12.43 y 15.45.
